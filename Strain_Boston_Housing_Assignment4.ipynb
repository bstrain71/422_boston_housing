{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Strain_Boston_Housing_Assignment4.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bstrain71/422_boston_housing/blob/master/Strain_Boston_Housing_Assignment4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nY11Ev7CuwTS",
        "colab_type": "text"
      },
      "source": [
        "## Ingest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScDaWkhIr3E8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import base packages into the namespace for this program\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import math\n",
        "import sklearn.model_selection\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "\n",
        "# read data from github\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/bstrain71/422_boston_housing/master/boston.csv')\n",
        "\n",
        "\n",
        "# remove neighborhood column IAW instructions\n",
        "df = df.drop(columns=['neighborhood'])\n",
        "\n",
        "base_df = df # save this to call column names, etc\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aqgz88xDuwcu",
        "colab_type": "text"
      },
      "source": [
        "## EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDK2pDmEGBVY",
        "colab_type": "code",
        "outputId": "176292b5-50cd-48c8-c284-fe227fc34623",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        }
      },
      "source": [
        "# i would like to predict the natural log vice the actual values\n",
        "df['mv'] = np.log(df['mv'])\n",
        "df = pd.DataFrame(df)\n",
        "\n",
        "print(df.shape)\n",
        "df.describe()"
      ],
      "execution_count": 285,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(506, 13)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>crim</th>\n",
              "      <th>zn</th>\n",
              "      <th>indus</th>\n",
              "      <th>chas</th>\n",
              "      <th>nox</th>\n",
              "      <th>rooms</th>\n",
              "      <th>age</th>\n",
              "      <th>dis</th>\n",
              "      <th>rad</th>\n",
              "      <th>tax</th>\n",
              "      <th>ptratio</th>\n",
              "      <th>lstat</th>\n",
              "      <th>mv</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.613524</td>\n",
              "      <td>11.363636</td>\n",
              "      <td>11.136779</td>\n",
              "      <td>0.069170</td>\n",
              "      <td>0.554695</td>\n",
              "      <td>6.284634</td>\n",
              "      <td>68.574901</td>\n",
              "      <td>3.795043</td>\n",
              "      <td>9.549407</td>\n",
              "      <td>408.237154</td>\n",
              "      <td>18.455534</td>\n",
              "      <td>12.653063</td>\n",
              "      <td>3.034558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>8.601545</td>\n",
              "      <td>23.322453</td>\n",
              "      <td>6.860353</td>\n",
              "      <td>0.253994</td>\n",
              "      <td>0.115878</td>\n",
              "      <td>0.702617</td>\n",
              "      <td>28.148861</td>\n",
              "      <td>2.105710</td>\n",
              "      <td>8.707259</td>\n",
              "      <td>168.537116</td>\n",
              "      <td>2.164946</td>\n",
              "      <td>7.141062</td>\n",
              "      <td>0.408275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.006320</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.460000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.385000</td>\n",
              "      <td>3.561000</td>\n",
              "      <td>2.900000</td>\n",
              "      <td>1.129600</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>187.000000</td>\n",
              "      <td>12.600000</td>\n",
              "      <td>1.730000</td>\n",
              "      <td>1.609438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.082045</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.190000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.449000</td>\n",
              "      <td>5.885500</td>\n",
              "      <td>45.025000</td>\n",
              "      <td>2.100175</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>279.000000</td>\n",
              "      <td>17.400000</td>\n",
              "      <td>6.950000</td>\n",
              "      <td>2.834680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.256510</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.690000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.538000</td>\n",
              "      <td>6.208500</td>\n",
              "      <td>77.500000</td>\n",
              "      <td>3.207450</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>330.000000</td>\n",
              "      <td>19.050000</td>\n",
              "      <td>11.360000</td>\n",
              "      <td>3.054001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3.677082</td>\n",
              "      <td>12.500000</td>\n",
              "      <td>18.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.624000</td>\n",
              "      <td>6.623500</td>\n",
              "      <td>94.075000</td>\n",
              "      <td>5.188425</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>666.000000</td>\n",
              "      <td>20.200000</td>\n",
              "      <td>16.955000</td>\n",
              "      <td>3.218876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>88.976200</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>27.740000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.871000</td>\n",
              "      <td>8.780000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>12.126500</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>711.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>37.970000</td>\n",
              "      <td>3.912023</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             crim          zn       indus  ...     ptratio       lstat          mv\n",
              "count  506.000000  506.000000  506.000000  ...  506.000000  506.000000  506.000000\n",
              "mean     3.613524   11.363636   11.136779  ...   18.455534   12.653063    3.034558\n",
              "std      8.601545   23.322453    6.860353  ...    2.164946    7.141062    0.408275\n",
              "min      0.006320    0.000000    0.460000  ...   12.600000    1.730000    1.609438\n",
              "25%      0.082045    0.000000    5.190000  ...   17.400000    6.950000    2.834680\n",
              "50%      0.256510    0.000000    9.690000  ...   19.050000   11.360000    3.054001\n",
              "75%      3.677082   12.500000   18.100000  ...   20.200000   16.955000    3.218876\n",
              "max     88.976200  100.000000   27.740000  ...   22.000000   37.970000    3.912023\n",
              "\n",
              "[8 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 285
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BX2T1XiEUcae",
        "colab_type": "code",
        "outputId": "5f550dab-ac37-49fb-bb0c-30906e9d366d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "source": [
        "# preprocess the data - scale everything to zero mean and unit variance\n",
        "# scale everything but the response variable\n",
        "no_response = df.drop(columns=['mv'])\n",
        "df_preprocessing = sklearn.preprocessing.scale(no_response)\n",
        "df = pd.concat((pd.DataFrame(df_preprocessing),\n",
        "                pd.DataFrame(df['mv'])),\n",
        "               axis = 1)\n",
        "\n",
        "df.columns = list(base_df.columns) \n",
        "\n",
        "df.describe()"
      ],
      "execution_count": 286,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>crim</th>\n",
              "      <th>zn</th>\n",
              "      <th>indus</th>\n",
              "      <th>chas</th>\n",
              "      <th>nox</th>\n",
              "      <th>rooms</th>\n",
              "      <th>age</th>\n",
              "      <th>dis</th>\n",
              "      <th>rad</th>\n",
              "      <th>tax</th>\n",
              "      <th>ptratio</th>\n",
              "      <th>lstat</th>\n",
              "      <th>mv</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5.060000e+02</td>\n",
              "      <td>5.060000e+02</td>\n",
              "      <td>5.060000e+02</td>\n",
              "      <td>5.060000e+02</td>\n",
              "      <td>5.060000e+02</td>\n",
              "      <td>5.060000e+02</td>\n",
              "      <td>5.060000e+02</td>\n",
              "      <td>5.060000e+02</td>\n",
              "      <td>5.060000e+02</td>\n",
              "      <td>5.060000e+02</td>\n",
              "      <td>5.060000e+02</td>\n",
              "      <td>5.060000e+02</td>\n",
              "      <td>506.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-8.688702e-17</td>\n",
              "      <td>3.306534e-16</td>\n",
              "      <td>2.804081e-16</td>\n",
              "      <td>-3.100287e-16</td>\n",
              "      <td>-8.071058e-16</td>\n",
              "      <td>-5.978968e-17</td>\n",
              "      <td>-2.650493e-16</td>\n",
              "      <td>8.293761e-17</td>\n",
              "      <td>1.514379e-15</td>\n",
              "      <td>-9.934960e-16</td>\n",
              "      <td>4.493551e-16</td>\n",
              "      <td>-1.595123e-16</td>\n",
              "      <td>3.034558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.000990e+00</td>\n",
              "      <td>1.000990e+00</td>\n",
              "      <td>1.000990e+00</td>\n",
              "      <td>1.000990e+00</td>\n",
              "      <td>1.000990e+00</td>\n",
              "      <td>1.000990e+00</td>\n",
              "      <td>1.000990e+00</td>\n",
              "      <td>1.000990e+00</td>\n",
              "      <td>1.000990e+00</td>\n",
              "      <td>1.000990e+00</td>\n",
              "      <td>1.000990e+00</td>\n",
              "      <td>1.000990e+00</td>\n",
              "      <td>0.408275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-4.197819e-01</td>\n",
              "      <td>-4.877224e-01</td>\n",
              "      <td>-1.557842e+00</td>\n",
              "      <td>-2.725986e-01</td>\n",
              "      <td>-1.465882e+00</td>\n",
              "      <td>-3.880249e+00</td>\n",
              "      <td>-2.335437e+00</td>\n",
              "      <td>-1.267069e+00</td>\n",
              "      <td>-9.828429e-01</td>\n",
              "      <td>-1.313990e+00</td>\n",
              "      <td>-2.707379e+00</td>\n",
              "      <td>-1.531127e+00</td>\n",
              "      <td>1.609438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-4.109696e-01</td>\n",
              "      <td>-4.877224e-01</td>\n",
              "      <td>-8.676906e-01</td>\n",
              "      <td>-2.725986e-01</td>\n",
              "      <td>-9.130288e-01</td>\n",
              "      <td>-5.686303e-01</td>\n",
              "      <td>-8.374480e-01</td>\n",
              "      <td>-8.056878e-01</td>\n",
              "      <td>-6.379618e-01</td>\n",
              "      <td>-7.675760e-01</td>\n",
              "      <td>-4.880391e-01</td>\n",
              "      <td>-7.994200e-01</td>\n",
              "      <td>2.834680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-3.906665e-01</td>\n",
              "      <td>-4.877224e-01</td>\n",
              "      <td>-2.110985e-01</td>\n",
              "      <td>-2.725986e-01</td>\n",
              "      <td>-1.442174e-01</td>\n",
              "      <td>-1.084655e-01</td>\n",
              "      <td>3.173816e-01</td>\n",
              "      <td>-2.793234e-01</td>\n",
              "      <td>-5.230014e-01</td>\n",
              "      <td>-4.646726e-01</td>\n",
              "      <td>2.748590e-01</td>\n",
              "      <td>-1.812536e-01</td>\n",
              "      <td>3.054001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>7.396560e-03</td>\n",
              "      <td>4.877224e-02</td>\n",
              "      <td>1.015999e+00</td>\n",
              "      <td>-2.725986e-01</td>\n",
              "      <td>5.986790e-01</td>\n",
              "      <td>4.827678e-01</td>\n",
              "      <td>9.067981e-01</td>\n",
              "      <td>6.623709e-01</td>\n",
              "      <td>1.661245e+00</td>\n",
              "      <td>1.530926e+00</td>\n",
              "      <td>8.065758e-01</td>\n",
              "      <td>6.030188e-01</td>\n",
              "      <td>3.218876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>9.933931e+00</td>\n",
              "      <td>3.804234e+00</td>\n",
              "      <td>2.422565e+00</td>\n",
              "      <td>3.668398e+00</td>\n",
              "      <td>2.732346e+00</td>\n",
              "      <td>3.555044e+00</td>\n",
              "      <td>1.117494e+00</td>\n",
              "      <td>3.960518e+00</td>\n",
              "      <td>1.661245e+00</td>\n",
              "      <td>1.798194e+00</td>\n",
              "      <td>1.638828e+00</td>\n",
              "      <td>3.548771e+00</td>\n",
              "      <td>3.912023</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               crim            zn  ...         lstat          mv\n",
              "count  5.060000e+02  5.060000e+02  ...  5.060000e+02  506.000000\n",
              "mean  -8.688702e-17  3.306534e-16  ... -1.595123e-16    3.034558\n",
              "std    1.000990e+00  1.000990e+00  ...  1.000990e+00    0.408275\n",
              "min   -4.197819e-01 -4.877224e-01  ... -1.531127e+00    1.609438\n",
              "25%   -4.109696e-01 -4.877224e-01  ... -7.994200e-01    2.834680\n",
              "50%   -3.906665e-01 -4.877224e-01  ... -1.812536e-01    3.054001\n",
              "75%    7.396560e-03  4.877224e-02  ...  6.030188e-01    3.218876\n",
              "max    9.933931e+00  3.804234e+00  ...  3.548771e+00    3.912023\n",
              "\n",
              "[8 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 286
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56NDZb30uwkC",
        "colab_type": "text"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESYiYaNFKnPy",
        "colab_type": "text"
      },
      "source": [
        "Goal for this assignment: do a pretty graph comparing the performance of the models. Maybe number of splits, pruning, something cool on x-axis?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DClCkB-1pcKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from sklearn.linear_model import Ridge"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "balhq9Nyonrb",
        "colab_type": "code",
        "outputId": "feb11e47-cbfb-4e7c-ece0-4ac61af466c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "# OLS\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "  df.loc[:,:'lstat'], df.loc[:,'mv'],\n",
        "    random_state=24601)\n",
        "\n",
        "# OLS regression\n",
        "ols = LinearRegression().fit(X_train, y_train)\n",
        "print(\"Training set score: {:.3f}\".format(ols.score(X_train, y_train)))\n",
        "print(\"Test set score: {:.3f}\".format(ols.score(X_test, y_test)))\n",
        "\n",
        "ols_predictions = pd.DataFrame(ols.predict(X_test))\n",
        "\n",
        "RMSE = sqrt(mean_squared_error(y_test, ols_predictions))\n",
        "print(\"RMSE:{:.3f}\".format(RMSE))\n",
        "\n",
        "# Ridge regression with all vars performed well. Let's cross validate this\n",
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(ols, df.loc[:,:'lstat'], df['mv'], cv=5)\n",
        "print(\"5-Fold Cross Valication Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(),\n",
        "                                                               scores.std() * 2))"
      ],
      "execution_count": 288,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set score: 0.793\n",
            "Test set score: 0.769\n",
            "RMSE:0.191\n",
            "5-Fold Cross Valication Accuracy: 0.62 (+/- 0.13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MTdvTb4TOxg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a873a7e8-aa9c-4ac9-fff4-dc335b4270a3"
      },
      "source": [
        "print(scores)"
      ],
      "execution_count": 289,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.70622803 0.68690075 0.5879571  0.56053291 0.54200121]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMpSW5w_o_RF",
        "colab_type": "code",
        "outputId": "b54f99c2-1612-4dca-cd8d-608666e7ba14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "# ridge regression\n",
        "ridge = Ridge(alpha = 10).fit(X_train, y_train)\n",
        "print(\"Training set score: {:.3f}\".format(ridge.score(X_train, y_train)))\n",
        "print(\"Test set score: {:.3f}\".format(ridge.score(X_test, y_test)))\n",
        "\n",
        "ridge_predictions = pd.DataFrame(ridge.predict(X_test))\n",
        "\n",
        "RMSE = sqrt(mean_squared_error(y_test, ridge_predictions))\n",
        "print(\"RMSE:{:.3f}\".format(RMSE))\n",
        "\n",
        "# Ridge regression cross validate\n",
        "scores = cross_val_score(ridge, df.loc[:,:'lstat'], df['mv'], cv=5)\n",
        "print(\"5-Fold Cross Valication Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "execution_count": 290,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set score: 0.792\n",
            "Test set score: 0.766\n",
            "RMSE:0.192\n",
            "5-Fold Cross Valication Accuracy: 0.63 (+/- 0.17)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlIDEBUZJI_n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "b7146b7a-3370-49e9-920a-c388a2f6b430"
      },
      "source": [
        "# random forest\n",
        "#math.log2(12) is approx 3.5 - round this to 4 for max_features\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "rforest = RandomForestRegressor(n_estimators = 100,\n",
        "                               max_depth = 7,\n",
        "                               max_features = 4,\n",
        "                               bootstrap = True).fit(X_train,y_train)\n",
        "print(\"Training set score: {:.3f}\".format(rforest.score(X_train, y_train)))\n",
        "print(\"Test set score: {:.3f}\".format(rforest.score(X_test, y_test)))\n",
        "\n",
        "rforest_predictions = pd.DataFrame(rforest.predict(X_test))\n",
        "\n",
        "RMSE = sqrt(mean_squared_error(y_test, rforest_predictions))\n",
        "print(\"RMSE:{:.3f}\".format(RMSE))\n",
        "\n",
        "# random forests cross valication\n",
        "scores = cross_val_score(rforest, df.loc[:,:'lstat'], df['mv'], cv=5)\n",
        "print(\"5-Fold Cross Valication Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(),\n",
        "                                                               scores.std() * 2))\n",
        "# random forest feature importance\n",
        "importances = rforest.feature_importances_\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "for name, score in zip(df, indices):\n",
        "        print(name, score)\n"
      ],
      "execution_count": 291,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set score: 0.960\n",
            "Test set score: 0.871\n",
            "RMSE:0.143\n",
            "5-Fold Cross Valication Accuracy: 0.69 (+/- 0.21)\n",
            "crim 11\n",
            "zn 5\n",
            "indus 0\n",
            "chas 4\n",
            "nox 10\n",
            "rooms 7\n",
            "age 9\n",
            "dis 2\n",
            "rad 6\n",
            "tax 8\n",
            "ptratio 1\n",
            "lstat 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRRdkC_iDMjF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "df1f4451-d5f8-489f-8081-183a47674f6c"
      },
      "source": [
        "std = np.std([tree.feature_importances_ for tree in rforest.estimators_],\n",
        "             axis=0)\n",
        "\n",
        "# Print the feature ranking\n",
        "print(\"Feature ranking:\")\n",
        "\n",
        "for f in range(X_train.shape[1]):\n",
        "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
        "\n",
        "# Plot the feature importances of the forest\n",
        "plt.figure()\n",
        "plt.title(\"Feature Importances\")\n",
        "plt.bar(range(X_train.shape[1]), importances[indices],\n",
        "       color=\"r\", yerr=std[indices], align=\"center\")\n",
        "plt.xticks(range(X_train.shape[1]), df.columns[indices], rotation = 'vertical')\n",
        "plt.xlim([-1, X_train.shape[1]])\n",
        "plt.show()"
      ],
      "execution_count": 292,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature ranking:\n",
            "1. feature 11 (0.324040)\n",
            "2. feature 5 (0.179107)\n",
            "3. feature 0 (0.168312)\n",
            "4. feature 4 (0.075086)\n",
            "5. feature 10 (0.062999)\n",
            "6. feature 7 (0.057665)\n",
            "7. feature 9 (0.052785)\n",
            "8. feature 2 (0.038811)\n",
            "9. feature 6 (0.026966)\n",
            "10. feature 8 (0.007497)\n",
            "11. feature 1 (0.004796)\n",
            "12. feature 3 (0.001938)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEfCAYAAAC6Z4bJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D94EfQlm893A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "fc440013-1f5f-4f35-e147-df4b2ed437f4"
      },
      "source": [
        "print(gbrt_best)"
      ],
      "execution_count": 293,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
            "                          learning_rate=0.1, loss='ls', max_depth=3,\n",
            "                          max_features=None, max_leaf_nodes=None,\n",
            "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                          min_samples_leaf=1, min_samples_split=2,\n",
            "                          min_weight_fraction_leaf=0.0, n_estimators=28,\n",
            "                          n_iter_no_change=None, presort='auto',\n",
            "                          random_state=None, subsample=1.0, tol=0.0001,\n",
            "                          validation_fraction=0.1, verbose=0, warm_start=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ghbdn-VGdFOb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "outputId": "03def973-5279-4d3f-f431-2e329d88ed76"
      },
      "source": [
        "# gradient boosting\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "#math.log2(12) approx 3.5 round this to 4\n",
        "gbrt = GradientBoostingRegressor(n_estimators = 100,\n",
        "                                 max_depth = 7,\n",
        "                                 max_features = 4).fit(X_train,y_train)\n",
        "\n",
        "errors = [mean_squared_error(y_test, y_pred)\n",
        "          for y_pred in gbrt.staged_predict(X_test)]\n",
        "bst_n_estimators = np.argmin(errors) + 1\n",
        "\n",
        "gbrt_best = GradientBoostingRegressor(n_estimators=bst_n_estimators)\n",
        "gbrt_best.fit(X_train, y_train)\n",
        "\n",
        "gbrt_best_predictions = pd.DataFrame(gbrt_best.predict(X_test))\n",
        "\n",
        "print(\"Training set score: {:.3f}\".format(gbrt_best.score(X_train, y_train)))\n",
        "print(\"Test set score: {:.3f}\".format(gbrt_best.score(X_test, y_test)))\n",
        "\n",
        "RMSE = sqrt(mean_squared_error(y_test, gbrt_best_predictions))\n",
        "print(\"RMSE:{:.3f}\".format(RMSE))\n",
        "\n",
        "# Ridge regression cross validate\n",
        "scores = cross_val_score(gbrt_best, df.loc[:,:'lstat'], df['mv'], cv=5)\n",
        "print(\"5-Fold Cross Valication Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
        "print(gbrt_best)"
      ],
      "execution_count": 299,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set score: 0.938\n",
            "Test set score: 0.851\n",
            "RMSE:0.153\n",
            "5-Fold Cross Valication Accuracy: 0.70 (+/- 0.15)\n",
            "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
            "                          learning_rate=0.1, loss='ls', max_depth=3,\n",
            "                          max_features=None, max_leaf_nodes=None,\n",
            "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                          min_samples_leaf=1, min_samples_split=2,\n",
            "                          min_weight_fraction_leaf=0.0, n_estimators=33,\n",
            "                          n_iter_no_change=None, presort='auto',\n",
            "                          random_state=None, subsample=1.0, tol=0.0001,\n",
            "                          validation_fraction=0.1, verbose=0, warm_start=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSNekwYECGlV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0fc0a1b6-32dc-4889-8a8a-9ab87c97de5a"
      },
      "source": [
        "# random forest feature importance\n",
        "importances = gbrt_best.feature_importances_\n",
        "indices = np.argsort(importances)[::-1]\n",
        "print(indices)\n",
        "# same indices as rforest feature importance - no need to plot again"
      ],
      "execution_count": 306,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[11  5  0  4  7 10  9  2  6  8  3  1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5q68vv1hE_KO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# correlations with mv - the response variable\n",
        "corr = df.corr()\n",
        "\n",
        "plt.figure(figsize=(13,13))\n",
        "sns.heatmap(corr[['mv']].\n",
        "            sort_values(by=['mv'],ascending=False),\n",
        "            vmin=-1,\n",
        "            cmap='coolwarm',\n",
        "            annot=True);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kM1lDiJuwvv",
        "colab_type": "text"
      },
      "source": [
        "## Conclusion"
      ]
    }
  ]
}